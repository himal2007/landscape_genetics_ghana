---
title: "Ghana prevalence data from ESPEN"
author: "Himal Shrestha"
date: "23/02/2022"
output: 
  md_document:
    variant: markdown_github
    toc: yes
    toc_depth: 4
---

```{r setup, echo=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/User/OneDrive - LA TROBE UNIVERSITY/1_Projects/transition_ghana_LG/landscape_genetics_ghana")
```

## Introduction
The data is obtained from [ESPEN database](https://espen.afro.who.int/tools-resources/download-data)

## Load libraries
```{r, message=FALSE}
extrafont::loadfonts(device="win", quiet = T)
```

```{r, message=FALSE}
suppressMessages({
  library(sf);
  library(tidyverse);
  # library(ggplot2);
  library(rgdal);
  # library(leaflet);
  library(raster);
  library(RColorBrewer);
  # library(tmap);
  # library(gstat);
  # library(tidyr);
  library(rgeos);
  library(ggspatial);
  library(INLA);
  library(INLAutils);
  library(tictoc);
  library(sp);
  library(cowplot);
  })
```

## Loading the data

```{r}
ghana_prev_site <- read.csv("data/data-GH-Oncho-sitelevel.csv", header = T)

ghana_prev_clean <- ghana_prev_site %>% filter(Georeliability == 1)

ghana_prev_clean2 <- ghana_prev_clean %>% dplyr::select(IU_NAME, IU_ID, LocationName, Longitude, Latitude, SurveyYear, Period, SurveyMonth, Method_0, Method_1, Method_2, Examined, Positive, Prevalence) %>% mutate(IU_NAME = as.factor(IU_NAME), IU_ID = as.numeric(IU_ID), LocationName = as.factor(LocationName), Longitude = as.numeric(Longitude), Latitude  = as.numeric(Latitude), SurveyYear = as.numeric(SurveyYear), SurveyMonth = as.factor(SurveyMonth), Period = as.factor(Period), Method_0 = as.factor(Method_0), Method_1 = as.factor(Method_1), Method_2 = as.factor(Method_2), Examined = as.numeric(Examined), Positive = as.numeric(Positive), Prevalence = as.numeric(Prevalence))

summary(ghana_prev_clean2)
# All the data from skin snipping - no REMO data

# Select the data used for mapping
ghana_prev_clean3 <- ghana_prev_clean2 %>% dplyr::select(Longitude, Latitude, SurveyYear, Period, Method_0, Examined, Positive, Prevalence) %>% mutate()

table(ghana_prev_clean3$Period, ghana_prev_clean3$Method_0)
# Most of the data that does not have the label were collected between 2006 - 2016
```

```{r}
## Ghana map boundary - level 1/updated
ghana_map_1 <- readOGR("data/gadm41_GHA_shp/gadm41_GHA_1.shp", verbose = FALSE) %>% st_as_sf()
```

### Convert to spatial object
```{r}
coordinates(ghana_prev_clean3) <- (ghana_prev_clean3[, c("Longitude","Latitude")])

ghana_prev_sf <- ghana_prev_clean3 %>% st_as_sf() 
st_crs(ghana_prev_sf) = 4326

# convert to UTM - planar CRS transformation
epsg_ghana_UTM <- 32630
st_crs(epsg_ghana_UTM)$proj4string
utm_proj_ghana <- st_crs(epsg_ghana_UTM)$proj4string  # "+proj=utm +zone=30 +datum=WGS84 +units=m +no_defs"

ghana_prev_sf <- ghana_prev_sf %>% st_transform(crs = utm_proj_ghana)
ghana_prev_sp <- as(ghana_prev_sf, "Spatial")
```


### Spatial filtering to transition region
```{r}
bbox_transition <- readRDS("data/bbox_buffer_transition_ghana.rds") %>% st_as_sf()

# filtering the prevalence data
GT_prev_sp <- intersect(x = ghana_prev_sp, y = bbox_transition)
```

```{r}
GT_prev_clean <- data.frame(GT_prev_sp)
GT_prev_clean <- GT_prev_clean %>% mutate(LONG = coords.x1, LAT = coords.x2, optional = NULL) %>% mutate(coords.x1 = NULL, coords.x2 = NULL, Longitude = NULL, Latitude = NULL)

## Omitting observations with missing data
GT_prev_clean <- na.omit(GT_prev_clean)

## Selecting only mapping data
GT_prev_mapping <- GT_prev_clean %>% filter(Method_0 == "Mapping")
```

### Find duplicate observations
```{r}
find_duplicate <- function(df){
  i <- duplicated(df[, c("LONG", "LAT")])
  long_dup <- df[i, ]$LONG
  lat_dup <- df[i, ]$LAT
  duplicate_sites <- df %>% filter(LONG %in% long_dup & LAT %in% lat_dup)
  return(duplicate_sites)
}

(duplicate_mf <- find_duplicate(df = GT_prev_mapping))
```

```{r}
GT_prev_mapdiff <- GT_prev_mapping[ !(GT_prev_mapping$LONG %in% duplicate_mf$LONG), ]
GT_prev_mapdiff %>% summary ## all collected before 2001
 
# Clean duplicate mf. If all the variables are same, keep only one observation. For, the ones with different prevalence, calculate average  
duplicate_mf2 <- duplicate_mf %>% distinct()
GT_unique_prev <- duplicate_mf2 %>% group_by(LONG, LAT) %>% summarise(Examined = sum(Examined), Positive = sum(Positive), Prevalence = Positive/Examined) 

## select required columns and merge the dataframe
GT_unique_prevmap <- GT_prev_mapdiff %>% dplyr::select(LONG, LAT, Examined, Positive, Prevalence) %>% rbind(GT_unique_prev)
```

## Visualise the prevalence data
### Prevalence histogram
```{r}
hist(GT_unique_prevmap$Prevalence, main = "",
     xlab="Onchocerciasis prevalence", ylab = ("Frequency"),
     border="black", 
     col="darkgrey", xlim=c(0,1), cex.lab=1.5, cex.axis=1, cex.main=2, cex.sub=2,
    #  ylim = c(0,225),
     las=1, 
     breaks=25)
```


### Ghana prevalence on a map
```{r}
# GT_prevmap_sf <- st_as_sf(x = GT_unique_prevmap, coords = c('LONG','LAT'), crs= "+proj=utm +zone=30 +datum=WGS84 +units=m +no_defs")

ghana_map_1_sfutm <- ghana_map_1 %>% st_transform(crs = "+proj=utm +zone=30 +datum=WGS84 +units=m +no_defs")
```

```{r}
mypalette <- colorRampPalette(rev(brewer.pal(11, "RdYlBu")))

p <- ggplot(ghana_map_1_sfutm) + 
  geom_sf(col = "black", lty = 1, alpha = 0.01) + coord_sf() +
  geom_sf(data = bbox_transition, alpha = 0) +
  geom_point(data = GT_unique_prevmap, aes(LONG, LAT, fill = Prevalence), color = "black", size = 2, stroke = 1, shape = 21, alpha = .7)+ labs(fill = "Onchocerciasis prevalence") +
  scale_fill_gradientn(colours = mypalette(100)) +
  scale_y_continuous(name=expression(paste("Latitude (",degree,")")), limits=c(844447.4, 973827),expand=c(0,0))+
  scale_x_continuous(name = expression(paste("Longitude (",degree,")")), limits=c(557845.6, 851520.9),expand=c(0,0)) + 
  annotation_scale(location = "br", width_hint = 0.5) +
  annotation_north_arrow(location = "tl", which_north = "true",
        pad_x = unit(0.05, "in"), pad_y = unit(0.05, "in"),
        style = north_arrow_fancy_orienteering) +
  theme_void(base_family = "Arial", base_size = 16) +
  theme(legend.position = "bottom", legend.key.size = unit(2, 'cm'), #change legend key size
        legend.key.height = unit(.5, 'cm'), #change legend key height
        legend.key.width = unit(1.5, 'cm')) +
  guides(fill = guide_colourbar(title.position="top", title.hjust = 0.5))

p
```


# Variable selection

## Loading the data
```{r}
cov_prev <- stack("data/220228_cov_prev.grd")
```

## Extract point data from raster covriates

```{r}
covs <- raster::extract(cov_prev, GT_unique_prevmap[c("LONG","LAT")], na.rm = TRUE, df = TRUE)

data_c_covs <- as.data.frame(cbind(GT_unique_prevmap, covs))
data_c_covs <- na.omit(data_c_covs)
data_c_covs %>% head()
```


## Prevalence data: Variable selection
```{r}
data_c_covs2 <- data_c_covs
data_c_covs[, c("Examined", "Positive", "LONG", "LAT", "ID")] <- NULL
```

```{r}
temp_covariates <- c(names(data_c_covs)[c(3:13, 22:23)], "Prevalence")
temp_data <- data_c_covs[, temp_covariates]

precip_covariates <- c(names(data_c_covs)[14:21], "Prevalence")
precip_data <- data_c_covs[, precip_covariates]

elev_data <- data_c_covs[, c("elevation", "slope", "Prevalence")]
vegind_data <- data_c_covs[, c("EVI01_GT_utm", "NDVI01_GT_utm", "Prevalence")]
hydro_data <- data_c_covs[, c("FC_GT_utm", "TCW01_GT_utm", "SM0001_GT_utm", "distwater_GT_utm", "Prevalence")]

sociodem_data <- data_c_covs[, c("popden0001_GT_utm",
                          "housing2001_GT_utm", "nightlights0001_GT_utm", "Prevalence")]
```

```{r}
covs_prev <- data_c_covs %>% dplyr::select(annual_mean_temperature, annual_diurnal_range, temperature_seasonality, maximum_temperature_warmest_month, minimum_temperature_coldest_month, temperature_annual_range, mean_temperature_wettest_quarter, mean_temperature_driest_quarter, mean_temperature_warmest_quarter, mean_temperature_coldest_quarter, isothermality, LST_day_01, LST_night_01, annual_precpitation, precipitation_wettest_month, precipitation_driest_month, precipitation_wettest_quarter, precipitation_dreist_quarter, precipitation_warmest_quarter, precipitation_coldest_quarter, precipitation_seasonality, elevation, slope, NDVI01_GT_utm, EVI01_GT_utm, FC_GT_utm, distwater_GT_utm, TCW01_GT_utm, SM0001_GT_utm, popden0001_GT_utm, housing2001_GT_utm, nightlights0001_GT_utm)

names(covs_prev) <- c("BIO1", "BIO2", paste0("BIO",4:11), "BIO3", paste0("BIO",c(12:14,16:19)), "BIO15", "LSTD", "LSTN", "DEM", "SLP", "NDVI", "EVI", "FC", "DW", "TCW", "SM", "PD", "IHP", "NL")
```

### PCA analysis

```{r}
library(FactoMineR)
library(factoextra)

res.pca <- PCA(covs_prev, scale.unit = TRUE, graph = FALSE)
p_pca <- fviz_pca_var(res.pca, col.var = "black") + ggtitle("")
p_pca
```

```{r}
# eig.val <- get_eigenvalue(res.pca)
```
```{r}
p_scree <- fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50)) + ggtitle("")
p_scree
```

```{r}
# var <- get_pca_var(res.pca)
```

```{r}
# p <- fviz_cos2(res.pca, choice = "var", axes = 1:3)
```


+ Upto 5 axis included because the cumulative variance explained is greater than 80%

```{r}
p_contrib <- fviz_contrib(res.pca, choice = "var", axes = 1:5, top = 100) + theme(axis.text.x = element_text(angle=90)) + ggtitle("")
p_contrib
```

#### Temperature variables

```{r}
corr <- cor(temp_data[, 1:13])
p.mat <- cor_pmat(temp_data[, 1:13])
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
p
```


+ `LST_night_01`, `annual_mean_temperature`, `temperature_annual_range`, `temperature_seasonality`, `minimum_temperature_coldest_month`

```{r}
temp_covselected <- c("LST_night_01", "annual_mean_temperature", "temperature_annual_range", "temperature_seasonality", "minimum_temperature_coldest_month")
temp_selected <- data_c_covs[,temp_covselected]
corr <- cor(temp_selected)
p.mat <- cor_pmat(temp_selected)
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
p
```

+ `temperature_annual_range` not included as it is correlated with `annual_mean_temperature` - > 0.6

```{r}
temp_covselected <- c("LST_night_01", "annual_mean_temperature", "temperature_seasonality", "minimum_temperature_coldest_month")
```

#### Precipitation variables

```{r}
corr <- cor(precip_data[, 1:8])
p.mat <- cor_pmat(precip_data[, 1:8])
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
p
```
```{r}
tree = hclustvar(X.quanti = precip_data[, 1:8])
plot(tree)
```
+ "precipitation_coldest_quarter", "annual_precpitation", "precipitation_warmest_quarter"

```{r}
precip_covselected <- c("precipitation_coldest_quarter", "annual_precpitation", "precipitation_warmest_quarter")
precip_selected <- data_c_covs[, precip_covselected]
corr <- cor(precip_selected)
p.mat <- cor_pmat(precip_selected)
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
```

+ `precipitation_warmest_quarter` excluded
```{r}
precip_covselected <- c("precipitation_coldest_quarter", "annual_precpitation")
```

#### Elevation/slope
```{r}
corr <- cor(elev_data[, 1:2])
p.mat <- cor_pmat(elev_data[, 1:2])
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
p
```
+ both selected
```{r}
elev_covselected <- c("elevation", "slope")
```

#### Vegind data
```{r}
corr <- cor(vegind_data[, 1:2])
p.mat <- cor_pmat(vegind_data[, 1:2])
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
p
```
+ `EVI01_GT_utm` selected
```{r}
vegind_covselected <- "EVI01_GT_utm"
```

#### Hydro data
```{r}
corr <- cor(hydro_data[, 1:4])
p.mat <- cor_pmat(hydro_data[, 1:4])
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
p
```
+ All selected
```{r}
hydro_covselected <- c("FC_GT_utm", "TCW01_GT_utm", "SM0001_GT_utm", "distwater_GT_utm")
```


#### Socio demographic data
```{r}
corr <- cor(sociodem_data[, 1:3])
p.mat <- cor_pmat(sociodem_data[, 1:4])
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
p
```
+ All selected
```{r}
sociodem_covselected <- c("popden0001_GT_utm", "housing2001_GT_utm", "nightlights0001_GT_utm")
```
#### Round 1 covs
```{r}
selected_covs_round1 <- c(temp_covselected, precip_covselected, elev_covselected, vegind_covselected, hydro_covselected, sociodem_covselected)
```
```{r}
corr <- cor(data_c_covs[, selected_covs_round1])
p.mat <- cor_pmat(data_c_covs[, selected_covs_round1])
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
p
```

+ `elevation`, `soil_moisture`, `EVI`, `popden0001_GT_utm` removed
```{r}
selected_covs_r1 <- selected_covs_round1[c(-7,-9,-12, -14)]
corr <- cor(data_c_covs[, selected_covs_r1])
p.mat <- cor_pmat(data_c_covs[, selected_covs_r1])
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
p
```
```{r}
prevcovs_selected <- cov_prev[[selected_covs_r1]]
```

+ annual mean temperature also removed - it's similar to LST and almost correlated to other variables
```{r}
selected_covs_r1 <- c("LST_night_01", "temperature_seasonality", "minimum_temperature_coldest_month", "precipitation_coldest_quarter", "annual_precpitation", "slope", "FC_GT_utm", "TCW01_GT_utm", "distwater_GT_utm", "housing2001_GT_utm", "nightlights0001_GT_utm")

data_c_selectedcovs <- data_c_covs[, selected_covs_r1]
data_c_selectedcovs$Prevalence <- data_c_covs$Prevalence

# prev_selectedcovs_long <- to_long(data = data_c_selectedcovs)
# prev_selectedcovs_long$Prevalence <- prev_selectedcovs_long$Prevalence * 100
# prev_selectedcovs_long$covariates <- as.factor(prev_selectedcovs_long$covariates)
```
+ night lights removed as majority of values 0
+ TCW removed all negative values in data
+ Soil moisture instead of precipitation at coldest quarter - interpretable

```{r}
selected_covs_r1 <- c("LST_night_01", "temperature_seasonality", "minimum_temperature_coldest_month", "SM0001_GT_utm", "annual_precpitation", "slope", "distwater_GT_utm", "housing2001_GT_utm")

selected_data <- data_c_covs[, selected_covs_r1]
names(selected_data) <- c("Land surface temp (night)", "Temperature seasonality", "Temperature coldest month (min)", "Soil moisture", "Annual precipitation", "Slope", "Distance to river", "Improved housing prevalence")
corr <- cor(selected_data)
p.mat <- cor_pmat(selected_data)
p <- ggcorrplot(corr, type = "lower", # p.mat = p.mat,
   lab = TRUE, digits = 2, insig = "blank")
p
```

# Model fitting and selection using INLA
We will be calculating different model fit metrics to assess the best model.
 + DIC
 + WAIC

### Loading the data
```{r}
prev_cols <- c("LONG", "LAT", "Examined", "Positive", "Prevalence")

data <- data_c_covs2[, c(prev_cols, selected_covs_r1)]
data <- data %>% mutate(X = NULL, N = Examined, CASES = Positive)

data$CASES <- round(data$CASES)
data$N <- round(data$N)
```

```{r}
# m <- readRDS("data/bbox_buffer_transition_ghana.rds") 
m <- bbox_transition %>% as_Spatial()

covariates <- stack("data/220228_cov_prev.grd")

varlist <- c("LST_night_01", "temperature_seasonality", "minimum_temperature_coldest_month", 
             "SM0001_GT_utm", "annual_precpitation", "slope", "distwater_GT_utm", "housing2001_GT_utm")

pred_data <- covariates[[varlist]]
pred_data <- aggregate(covariates[[varlist]], fact = 2, fun = mean, na.rm = TRUE)  # 2km grid for prediction

ra <- pred_data
dp <- data.frame(rasterToPoints(ra))
```


```{r}
coords <-  cbind(data$LONG, data$LAT)
bdry <- inla.sp2segment(m)
bdry$loc <- inla.mesh.map(bdry$loc)

mesh5 <- inla.mesh.2d(
  loc = coords, boundary = bdry, 
  max.edge = c(15000, 100000),
  cutoff = 7500
)
mesh5$n
mesh5_plot <- autoplot(mesh5) + theme_void() + theme(legend.position = "none")
```

### SPDE and A matrix

```{r}
A <- inla.spde.make.A(mesh = mesh5, loc = as.matrix(coords)); dim(A)
spde <- inla.spde2.matern(mesh5, alpha=2)

iset <- inla.spde.make.index(name = "spatial.field", spde$n.spde)
length(iset)
```

### INLA stack
```{r}
df <- data.frame(Intercept = 1, subset(data, select = varlist))

stk <- inla.stack(
    tag = "est",
    data = list(y = data$CASES, numtrials = data$N),
    A = list(1, A),
    effects = list(df, spatial.field = iset)
  )
```

### Model fitting
```{r}
formula01 <-y ~ -1 + Intercept 
formula0 <-y ~ -1 + Intercept + f(spatial.field, model=spde)
# + Soil_moisture + Flow_accumulation + near_river_DIVA + night_lights + mean_housing_2000_15 + Population_density + annual_diurnal_range + annual_precp + f(spatial.field, model=spde) 
```

#### Binomial
```{r}
tic()
inla.setOption(num.threads = 12)
model01.binom <- inla(formula01,
            family = "binomial", Ntrials = numtrials,
            data = inla.stack.data(stk, spde = spde),
            control.family = list(link = "logit"),
            control.compute = list(dic = TRUE, waic = TRUE,
                                   cpo = TRUE, config = TRUE,
                                   openmp.strategy="huge"),
            control.predictor = list(
              compute = TRUE, link = 1,
              A = inla.stack.A(stk)
            )
  )
toc()

tic()
inla.setOption(num.threads = 12)
model.binom <- inla(formula0,
            family = "binomial", Ntrials = numtrials,
            data = inla.stack.data(stk, spde = spde),
            control.family = list(link = "logit"),
            control.compute = list(dic = TRUE, waic = TRUE,
                                   cpo = TRUE, config = TRUE,
                                   openmp.strategy="huge"),
            control.predictor = list(
              compute = TRUE, link = 1,
              A = inla.stack.A(stk)
            )
  )
toc()
```
```{r}
model_stats <- tibble(Models = c("Binomial without spatial","Binomial"),
       DIC = c(model01.binom$dic$dic, model.binom$dic$dic),
       WAIC = c(model01.binom$waic$waic, model.binom$waic$waic)) 
model_stats # going for a spatial model
```

## Testing Meshes
### Fine tuning mesh
```{r}
### mesh A
meshA <- inla.mesh.2d(
  loc = coords, boundary = bdry, max.edge = c(10000, 100000),
  cutoff = 3000
)
meshA$n
meshA_plot <- autoplot(meshA) + theme_void() + theme(legend.position = "none")

### mesh B
meshB <- inla.mesh.2d(
  loc = coords, boundary = bdry, max.edge = c(15000, 100000),
  cutoff = 5000
)
meshB$n
meshB_plot <- autoplot(meshB) + theme_void() + theme(legend.position = "none")

### mesh C
meshC <- inla.mesh.2d(
  loc = coords, boundary = bdry, max.edge = c(10000, 50000),
  cutoff = 5000
)
meshC$n
meshC_plot <- autoplot(meshC) + theme_void() + theme(legend.position = "none")

### mesh D
meshD <- inla.mesh.2d(
  loc = coords, boundary = bdry, max.edge = c(15000, 50000),
  cutoff = 7500
)
meshD$n
meshD_plot <- autoplot(meshD) + theme_void() + theme(legend.position = "none")

### mesh E
meshE <- inla.mesh.2d(
  loc = coords, boundary = bdry, max.edge = c(5000, 100000),
  cutoff = 3000
)
meshE$n
meshE_plot <- autoplot(meshE) + theme_void() + theme(legend.position = "none")

### mesh F
meshF <- inla.mesh.2d(
  loc = coords, boundary = bdry, max.edge = c(7500, 150000),
  cutoff = 6000
)
meshF$n
meshF_plot <- autoplot(meshF) + theme_void() + theme(legend.position = "none")

meshes <- plot_grid(meshA_plot, meshB_plot, meshC_plot, meshD_plot, meshE_plot, meshF_plot, labels = "AUTO")

meshes

ggsave(plot = meshes, filename = "figs/triangulation_meshes.png", device = "png", dpi = 500, width = 10, height = 5, units = "in", bg = "white" )
```

##### Running model on different meshes
```{r}
# custom function for stacking the data
stack_data <- function(data, dp, cov_list){
  # stack for estimation stk.e
  df <- data.frame(b0 = 1, subset(data, select = cov_list))
  stk.e <- inla.stack(
    tag = "est",
    data = list(y = data$CASES, numtrials = data$N),
    A = list(1, A),
    effects = list(df, spatial.field = indexs)
  )
  
  # stack for prediction stk.p
  df_p <- data.frame(b0 = 1, subset(dp, select = cov_list))
  stk.p <- inla.stack(
    tag = "pred",
    data = list(y = NA, numtrials = NA),
    A = list(1, Ap),
    effects = list(df_p, spatial.field = indexs))
  
  # stk.full has stk.e and stk.p
  stk.full <- inla.stack(stk.e, stk.p)
  
  return(stk.full)
}
```

```{r}
df_1 <- data.frame(Meshes = LETTERS[1:6],
                   DIC = NA,
                   WAIC = NA,
                   time_taken = NA,
                   number_p = NA,
                   mean_sd = NA)
pred_res <- list()

meshes <- list(meshA, meshB, meshC, meshD, meshE, meshF)
ra <- aggregate(covariates[[varlist]], fact = 25, fun = mean, na.rm = TRUE)  # 2km grid for prediction
dp <- data.frame(rasterToPoints(ra))
coop <- cbind(dp$x, dp$y)

predterms <- as.formula(paste("y ~ 0 + b0 +", paste(varlist, collapse =  "+"), "+ f(spatial.field, model = spde)"))

pb = txtProgressBar(min = 0, max = length(meshes), initial = 0) 

for (i in 1:length(meshes)) {
  spde <- inla.spde2.matern(meshes[[i]], alpha=2)
  indexs <- inla.spde.make.index(name = "spatial.field", spde$n.spde)
  A <- inla.spde.make.A(mesh = meshes[[i]], loc = as.matrix(coords)); dim(A)
  Ap <- inla.spde.make.A(mesh = meshes[[i]], loc = coop);dim(Ap)
  datastack <- stack_data(data = data, dp = dp, cov_list = varlist)
  inla.setOption(num.threads = 12)
  old <- Sys.time()
  p.res <- inla(predterms,
            family = "binomial", Ntrials = numtrials,
            data = inla.stack.data(datastack, spde = spde),
            control.family = list(link = "logit"),
            control.compute = list(dic = TRUE, waic = TRUE,
                                   cpo = TRUE, config = TRUE,
                                   openmp.strategy="huge"),
            control.predictor = list(
              compute = TRUE, link = 1,
              A = inla.stack.A(datastack)
            )
)
  df_1[i, 4] <- Sys.time() - old
  df_1[i, 2] <- p.res$dic$dic
  df_1[i, 3] <- p.res$waic$waic
  df_1[i, 5] <- meshes[[i]]$n
  
  index <- inla.stack.index(stack = datastack, tag = "pred")$data
  prev_mean <- p.res$summary.fitted.values[index, "mean"]
  prev_sd <-  p.res$summary.fitted.values[index, "sd"]
  pred_res[[i]] <- list(prev_mean, prev_sd)
  df_1[i, 6] <- mean(prev_sd)
  setTxtProgressBar(pb,i)
  cat("\nIteration = ", i, "\n")
  print(Sys.time() - old)
}

df_1

# df_1 %>% write.csv("data/220310_model_meshes.csv")
```

```{r}
df_2 <- data.frame(Meshes = LETTERS[1:6],
                   mean_sd = NA,
                   range_sd = )
```



+ custom function for stacking the data
```{r}
stack_data <- function(data, dp, cov_list){
  # stack for estimation stk.e
  df <- data.frame(Intercept = 1, subset(data, select = cov_list))
  stk.e <- inla.stack(
    tag = "est",
    data = list(y = data$CASES, numtrials = data$N),
    A = list(1, Ae),
    effects = list(df, spatial.field = iset)
  )
  
  # stack for prediction stk.p
  df_p <- data.frame(Intercept = 1, subset(dp, select = cov_list))
  stk.p <- inla.stack(
    tag = "pred",
    data = list(y = dp$CASES, numtrials = dp$N),
    A = list(1, Ap),
    effects = list(df_p, spatial.field = iset))
  
  # stk.full has stk.e and stk.p
  stk.full <- inla.stack(stk.e, stk.p)
  
  return(stk.full)
}
```
+ running the model on the data and predicting the same data
```{r}
train <- data; test <- data
test_coords <- train_coords <- coords

# A <- inla.spde.make.A(mesh=mesh5,loc=as.matrix(train_coords));dim(A)

Ae <- inla.spde.make.A(mesh=mesh5,loc=as.matrix(train_coords));dim(Ae)
Ap <- inla.spde.make.A(mesh = mesh5, loc = test_coords);dim(Ap)
stk.full <- stack_data(data = train, dp = test, cov_list = varlist)


inla.setOption(num.threads = 12)
tic()
p.res <- inla(predterms,
            family = "binomial", Ntrials = numtrials,
            data = inla.stack.data(stk.full, spde = spde),
            control.family = list(link = "logit"),
            control.compute = list(dic = TRUE, waic = TRUE,
                                   cpo = TRUE, config = TRUE,
                                   openmp.strategy="huge"),
            control.predictor = list(
              compute = TRUE, link = 1,
              A = inla.stack.A(stk.full)
            )
  )
toc()

index.pred <- inla.stack.index(stk.full, "pred")$data
obs_prev <- train$Prevalence #this is the number pos/number examined
pred_mean <- p.res$summary.fitted.values[index.pred, "mean"]
# pred_mean <- pred_mean * 100
pred_sd = p.res$summary.fitted.values[index.pred,"sd"]
validation = list()
validation$res = obs_prev - pred_mean 
validation$rmse = sqrt(mean(validation$res^2, na.rm=TRUE)) 
validation$cor = cor(obs_prev, pred_mean, 
                       use="pairwise.complete.obs",
                       method="spearman")

Efxplot(p.res, ModelNames = "Model 2")
```

### K-fold cross validation

+ Output RMSE and correlation ceofficient
+ Output validation data with observed and predicted values
+ Not much data so might not be suitable

```{r}
varlist <- c("LST_night_01", "temperature_seasonality", "minimum_temperature_coldest_month", 
             "SM0001_GT_utm", "annual_precpitation", "slope", "distwater_GT_utm", "housing2001_GT_utm")
```

```{r}
library(dismo)
fold <- 10 # specify fold
model <- 1 # specify model
variables = 2
pb = txtProgressBar(min = 0, max = fold, initial = 0) 
output <- matrix(ncol=variables, nrow=fold)
colnames(output) <- c("RMSE", "Correlation-coefficient")
output <- data.frame(output)

set.seed(12345)
kf <- kfold(nrow(data), k = fold)

predterms <- as.formula(paste("y ~ 0 + Intercept +", paste(varlist, collapse =  "+"), "+ f(spatial.field, model = spde)"))

old <- Sys.time()
for(i in 1:fold) {
  test <- data[kf == i, ]
  train <- data[kf != i, ]
  test$CASES <- NA  #make the y values for test NA
  test_coords <- coords[kf == i,]
  train_coords <- coords[kf != i,]
  Ae <- inla.spde.make.A(mesh=mesh5,loc=as.matrix(train_coords));dim(Ae)
  Ap <- inla.spde.make.A(mesh = mesh5, loc = test_coords);dim(Ap)
  stk.full <- stack_data(data = train, dp = test, cov_list = varlist)
  inla.setOption(num.threads = 8)
  p.res <- inla(predterms,
            family = "binomial", Ntrials = numtrials,
            data = inla.stack.data(stk.full, spde = spde),
            control.family = list(link = "logit"),
            control.compute = list(dic = TRUE, waic = TRUE,
                                   cpo = TRUE, config = TRUE,
                                   openmp.strategy="huge"),
            control.predictor = list(
              compute = TRUE, link = 1,
              A = inla.stack.A(stk.full)
            )
  )
  index.pred <- inla.stack.index(stk.full, "pred")$data
  obs_prev <- test$Prevalence #this is the number pos/number examined
  pred_mean <- p.res$summary.fitted.values[index.pred, "mean"]
  pred_sd = p.res$summary.fitted.values[index.pred,"sd"]
  validation = list()
  validation$res = obs_prev - pred_mean 
  validation$rmse = sqrt(mean(validation$res^2, na.rm=TRUE)) 
  validation$cor = cor(obs_prev, pred_mean, 
                       use="pairwise.complete.obs",
                       method="spearman")
  output[i, ] <- c(validation$rmse, validation$cor)
  
  if(i == 1){
      object_cor <- data.frame(fold = i, pred_mean, obs_prev)
    }
    else{
      object_cor <- bind_rows(object_cor, data.frame(fold = i, pred_mean, obs_prev))
    }
    setTxtProgressBar(pb,i)
    cat("\nIteration = ", i, "\n")
    print(Sys.time() - old)
}

# write.csv(output, paste0("data/validation_stats_", "model_",model, "_", "fold_", fold,".csv"))
# write.csv(object_cor, paste0("data/obs_pred_val_","model_",model, "_", "fold_", fold,".csv"))

val_stats <- data.frame(RMSE = mean(output$RMSE), Corr_coff = mean(output$Correlation.coefficient))
# write.csv(val_stats, "docs/valid_cor.csv")
save(output, object_cor, val_stats, file = "docs/validation_stats.RData")

load("docs/validation_stats.RData")
```
